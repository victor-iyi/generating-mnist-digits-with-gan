{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network (DCGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime.datetime as datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import ImageDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data & save directory.\n",
    "data_dir, save_dir = 'datasets/flowers/', 'saved/'\n",
    "save_data = os.path.join(save_dir, 'data.pkl')\n",
    "\n",
    "# Preprocess image data.\n",
    "data = ImageDataset(data_dir=data_dir, size=50, flatten=False, grayscale=False)\n",
    "\n",
    "# Create data if it's not yet saved, otherwise; load it.\n",
    "if os.path.isfile(save_data):\n",
    "    data = data.load(save_data)\n",
    "else:\n",
    "    data.create()\n",
    "    data.save(save_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split samples into training and testing sets.\n",
    "X_train, _, X_test, _ = data.train_test_split(test_size=0.1)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = data.size\n",
    "image_channel = data.channels\n",
    "image_size_flat = image_size * image_size * image_channel\n",
    "print('size: {}\\tchannel: {}\\t flattened: {:,}'.format(image_size, image_channel, image_size_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = 0.8\n",
    "\n",
    "# Training.\n",
    "learning_rate = 1e-3\n",
    "batch_size = 24\n",
    "iterations = 10000   # 10k\n",
    "save_interval = 100  # 100\n",
    "log_interval = 1000  # 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(imgs, name=None):\n",
    "    grid = int(np.sqrt(len(imgs)))\n",
    "    fig, axes = plt.subplots(grid, grid)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    if name:\n",
    "        plt.suptitle(name)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(imgs[i].reshape([image_size, image_size]), cmap='binary', interpolation='bicubic')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator `(Deep Convolutional Neural Net)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(image, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Building 'AlexNet'\n",
    "        network = tf.reshape(image, shape=[-1, image_size, image_size, image_channel])\n",
    "        # 1st convnet\n",
    "        network = tflearn.conv_2d(network, nb_filter=16, filter_size=11, strides=4, activation='relu',)\n",
    "        network = tflearn.max_pool_2d(network, kernel_size=3, strides=2)\n",
    "        network = tflearn.batch_normalization(network)\n",
    "        # 2nd convnet\n",
    "        network = tflearn.conv_2d(network, nb_filter=32, filter_size=5, activation='relu')\n",
    "        network = tflearn.max_pool_2d(network, kernel_size=3, strides=2)\n",
    "        network = tflearn.batch_normalization(network)\n",
    "        # 3, 4, 5 convnet\n",
    "        network = tflearn.conv_2d(network, nb_filter=64, filter_size=3, activation='relu')\n",
    "        network = tflearn.conv_2d(network, nb_filter=128, filter_size=3, activation='relu')\n",
    "        network = tflearn.conv_2d(network, nb_filter=64, filter_size=3, activation='relu')\n",
    "        network = tflearn.max_pool_2d(network, kernel_size=3, strides=2)\n",
    "        network = tflearn.batch_normalization(network)\n",
    "        # Flatten\n",
    "        network = tflearn.flatten(network)\n",
    "        # 1st fully connected\n",
    "        network = tflearn.fully_connected(network, n_units=256, activation='tanh')\n",
    "        network = tflearn.dropout(network, keep_prob)\n",
    "        # 2nd fully connected\n",
    "        network = tflearn.fully_connected(network, n_units=128, activation='tanh')\n",
    "        network = tflearn.dropout(network, keep_prob)\n",
    "        # 3rd fully connected\n",
    "        network = tflearn.fully_connected(network, n_units=1, activation='linear')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator `(Deep Deconvolutional Neural Net)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(noise, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        x = tflearn.fully_connected(noise, n_units=256, activation='tanh')\n",
    "        x = tflearn.batch_normalization(x)\n",
    "        x = tflearn.fully_connected(x, n_units=1024, activation='tanh')  # 8*8*16=1024\n",
    "        x = tf.reshape(x, shape=[-1, 8, 8, 16])\n",
    "        x = tflearn.upsample_2d(x, 2)\n",
    "        x = tflearn.conv_2d(x, nb_filter=64,  filter_size=5, activation='relu')\n",
    "        x = tflearn.conv_2d(x, nb_filter=128, filter_size=5, activation='relu')\n",
    "        x = tflearn.conv_2d(x, nb_filter=64,  filter_size=5, activation='relu')\n",
    "        x = tflearn.batch_normalization(x)\n",
    "        x = tflearn.upsample_2d(x, kernel_size=2)\n",
    "        x = tflearn.conv_2d(x, nb_filter=32, filter_size=5, activation='relu')\n",
    "        x = tflearn.batch_normalization(x)\n",
    "        x = tflearn.conv_2d(x, nb_filter=image_size_flat, filter_size=5, activation='relu')\n",
    "        x = tflearn.upsample_2d(x, kernel_size=2)\n",
    "        x = tflearn.conv_2d(x, nb_filter=16, filter_size=5, activation='relu')\n",
    "        x = tflearn.layers.flatten(x)\n",
    "        x = tflearn.fully_connected(x, n_units=image_size_flat, activation='sigmoid')\n",
    "        x = tf.reshape(x, shape=[-1, image_size, image_size, image_channel])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 200\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# gen_input = tflearn.input_data(shape=[None, z_dim], name='input_noise')\n",
    "# disc_input = tflearn.input_data(shape=[None, image_size_flat], name='disc_input')\n",
    "\n",
    "X_placeholder = tf.placeholder(tf.float32, shape=[None, image_size_flat], name='X_placeholder')\n",
    "Z_placeholder = tf.placeholder(tf.float32, shape=[None, z_dim], name='Z_placeholder')\n",
    "\n",
    "Gz = generator(Z_placeholder)\n",
    "Dx = discriminator(X_placeholder)\n",
    "Dg = discriminator(Gz, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator's loss\n",
    "with tf.name_scope('disc_loss'):\n",
    "    # Real.\n",
    "    d_real_loss = tf.nn.softmax_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx))\n",
    "    d_real_loss = tf.reduce_mean(d_real_loss, name='real_loss')\n",
    "    # Fake.\n",
    "    d_fake_loss = tf.nn.softmax_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg))\n",
    "    d_fake_loss = tf.reduce_mean(d_fake_loss, name='fake_loss')\n",
    "\n",
    "# Generator's loss\n",
    "with tf.name_scope('gen_loss'):\n",
    "    gen_loss = tf.nn.softmax_cross_entropy_with_logits(logits=Gz, labels=tf.ones_like(Gz))\n",
    "    gen_loss = tf.reduce_mean(gen_loss, name='gen_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variables for the discriminator & generator\n",
    "dis_vars = tflearn.get_layer_variables_by_scope('discriminator')\n",
    "gen_vars = tflearn.get_layer_variables_by_scope('generator')\n",
    "\n",
    "\n",
    "# Discriminator's optimizer.\n",
    "with tf.name_scope('disc_optimizer'):\n",
    "    # Real discriminator optimizer.\n",
    "    global_step_real = tf.Variable(0, trainable=False, name='global_step_real')\n",
    "    disc_opt_real = tf.train.AdadeltaOptimizer(learning_rate=learning_rate)\n",
    "    disc_opt_real = disc_opt_real.minimize(d_real_loss, var_list=dis_vars,\n",
    "                                           global_step=global_step_real)\n",
    "    \n",
    "    # Fake discriminator optimizer.\n",
    "    global_step_fake = tf.Variable(0, trainable=False, name='global_step_fake')\n",
    "    disc_opt_fake = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    disc_opt_fake = disc_opt_fake.minimize(d_fake_loss, var_list=dis_vars,\n",
    "                                           global_step=global_step_fake)\n",
    "\n",
    "# Generator's Optimizer.\n",
    "with tf.name_scope('gen_optimizer'):\n",
    "    gen_global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    gen_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    gen_optimizer = gen_optimizer.minimize(gen_loss, var_list=gen_vars,\n",
    "                                           global_step=gen_global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow `Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_dir = os.path.join(save_dir, 'tensorboard/')\n",
    "logdir = os.path.join(tensorboard_dir, 'log/')\n",
    "\n",
    "save_dir = os.path.join(save_dir, 'models/')\n",
    "save_path = os.path.join(save_path, 'model.ckpt')\n",
    "\n",
    "\n",
    "# Tensorboard sumamry.\n",
    "with tf.name_scope('summary'):\n",
    "    # Scalar summary.\n",
    "    tf.summary.scalar('discriminator_loss_real', d_real_loss)\n",
    "    tf.summary.scalar('discriminator_loss_fake', d_fake_loss)\n",
    "    tf.summary.scalar('discriminator_add_loss', d_real_loss + d_fake_loss)\n",
    "    tf.summary.scalar('generator_loss', gen_loss)\n",
    "    \n",
    "    # Image summary.\n",
    "    tb_img = generator(Z_placeholder, reuse=True)  # Tensorboard image\n",
    "    tf.summary.image('generator_image', tb_img, max_outputs=4)\n",
    "\n",
    "\n",
    "# Saver & Writer object.\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring  last checkpoint.\n",
    "if tf.gfile.Exists(save_dir):\n",
    "    try:\n",
    "        print('INFO: Attempting to restore last checkpoint!')\n",
    "        last_ckpt = tf.train.latest_checkpoint(save_dir)\n",
    "        \n",
    "        # Restoring last checkpoint into default graph.\n",
    "        saver.restore(sess=sess, save_path=last_ckpt)\n",
    "        print('INFO: Checkpoint restored! @{}'.format(last_ckpt))\n",
    "    except Exception as e:\n",
    "        print('WARNING: Could not retrieve last checkpoint. {}'.format(e))\n",
    "else:\n",
    "    tf.gfile.MakeDirs(save_dir)\n",
    "    print('INFO: Created checkpoint directory - {}'.format(save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start the discriminator training clock.\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "# Initial discriminator training.\n",
    "for i in range(1, 101):\n",
    "    try:\n",
    "        # Retrive training batches.\n",
    "        fake_batch = np.random.normal(0, 1, [batch_size, z_dim])\n",
    "        real_batch = data.next_batch(batch_size=batch_size)[0]\n",
    "        real_batch = np.reshape(real_batch, [-1, image_size_flat])\n",
    "\n",
    "        # Train the discriminator model.\n",
    "        _, _, _fake_loss, _real_loss = sess.run([disc_opt_fake, disc_opt_real, \n",
    "                                                 d_fake_loss, d_real_loss],\n",
    "                                                feed_dict={X_placeholder: real_batch, \n",
    "                                                           Z_placeholder: fake_batch})\n",
    "\n",
    "        # Log progress.\n",
    "        print(f'\\rIter: {i:,}\\tLoss:-real: {_real_loss:.4f}'\n",
    "              f'\\tfake: {_fake_loss:.4f}\\tTime taken = '\n",
    "              f'{datetime.now() - start_time}', end='')\n",
    "    except KeyboardInterrupt:\n",
    "        print('Training stopped!')\n",
    "        \n",
    "        # End the loop smoothly.\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start the training clock.\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Training the discriminator & generator together.\n",
    "for i in range(1, iterations+1):\n",
    "    try:\n",
    "        # Train discriminator on real & fake images.\n",
    "        fake_batch = np.random.normal(0, 1, size=[batch_size, z_dim])\n",
    "        real_batch = data.next_batch(batch_size=batch_size)[0]\n",
    "        real_batch = np.reshape(real_batch, [-1, image_size_flat])\n",
    "\n",
    "        # Train the discriminator.\n",
    "        _, _, _fake_loss, _real_loss = sess.run([disc_opt_fake, disc_opt_real, \n",
    "                                                 d_fake_loss, d_real_loss],\n",
    "                                                    feed_dict={X_placeholder: real_batch, \n",
    "                                                               Z_placeholder: fake_batch})\n",
    "\n",
    "        # Train generator to generate images.\n",
    "        gen_img = np.random.normal(0, 1, size=[batch_size, z_dim])\n",
    "        _, _gen_loss, _global_gen = sess.run([gen_optimizer, gen_loss, gen_global_step], \n",
    "                                             feed_dict={Z_placeholder: gen_img})\n",
    "\n",
    "        # Saving.\n",
    "        if i % save_interval == 0:\n",
    "            # Save the generative model.\n",
    "            saver.save(sess=sess, save_path=save_path, global_step=gen_global_step)\n",
    "            # Update tensorboard.\n",
    "            summary = sess.run(merged, feed_dict={X_placeholder: real_batch,\n",
    "                                                  Z_placeholder:fake_batch})\n",
    "            writer.add_summary(summary=summary, global_step=_global_gen)\n",
    "\n",
    "        # Logging: Displaying generated images @ intervals.\n",
    "        if i % log_interval == 0:\n",
    "            test_noise  = np.random.normal(0, 1, size=[9, z_dim])\n",
    "            gen_test = generator(Z_placeholder)\n",
    "            test_imgs = sess.run(gen_test, feed_dict={Z_placeholder: test_noise})\n",
    "            plot_images(test_imgs, name='Iteration: {:,}\\tTest image'.format(i))\n",
    "\n",
    "        # Log training metrics.\n",
    "        print(f'\\rIter: {i:,}\\tGen loss: {_gen_loss:.4f}'\n",
    "              f'\\tDiscriminator: real = {_real_loss:.4f}'\n",
    "              f'\\tfake = {_fake_loss:.4f}\\tTime taken: '\n",
    "              '{datetime.now() - start_time}', end='')\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        # End training interruption smoothly.\n",
    "        print(f'Training stopped @ iter {i:,}. Saving model.')\n",
    "        \n",
    "        # Save the generative model.\n",
    "        saver.save(sess=sess, save_path=save_path, global_step=gen_global_step)\n",
    "        \n",
    "        # Update tensorboard.\n",
    "        summary = sess.run(merged, feed_dict={X_placeholder: real_batch,\n",
    "                                      Z_placeholder:fake_batch})\n",
    "        writer.add_summary(summary=summary, global_step=_global_gen)\n",
    "        \n",
    "        print('Model saved! Ending training.')\n",
    "        \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
