{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network (DCGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('datasets/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "image_size = 28\n",
    "image_channel = 1\n",
    "image_size_flat = image_size * image_size * image_channel\n",
    "\n",
    "# Network\n",
    "filter_size = 5\n",
    "deconv_filter = 3\n",
    "conv1_size = 16\n",
    "conv2_size = 32\n",
    "conv3_size = 128\n",
    "fc1_size = 512\n",
    "fc2_size = 256\n",
    "fc3_size = 1\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-2\n",
    "batch_size = 24\n",
    "iterations = 10000\n",
    "save_interval = 100\n",
    "log_interval = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(imgs, size=28, name=None):\n",
    "    grid = int(np.sqrt(len(imgs)))\n",
    "    fig, axes = plt.subplots(grid, grid)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    if name:\n",
    "        plt.suptitle(name)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(imgs[i].reshape([size, size]), cmap='binary', interpolation='bicubic')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# def weight(shape, name):\n",
    "#     initial = tf.truncated_normal(shape=shape, mean=0, stddev=0.4)\n",
    "#     return tf.Variable(initial, name=name)\n",
    "\n",
    "# def bias(shape, name):\n",
    "#     initial = tf.zeros(shape=[shape])\n",
    "#     return tf.Variable(initial, name=name)\n",
    "\n",
    "# Weight initializer\n",
    "def weight(shape, name):\n",
    "    return tf.get_variable(name, shape, initializer=tf.truncated_normal_initializer(stddev=0.2))\n",
    "\n",
    "# Bias initializer\n",
    "def bias(shape, name):\n",
    "    return tf.get_variable(name, [shape], initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "def conv_block(layer, W, b):\n",
    "    layer = tf.nn.conv2d(layer, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    layer = layer + b  # add bias\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return layer\n",
    "# Convolutional block\n",
    "def conv_block(layer, W, b):\n",
    "    layer = tf.nn.conv2d(layer, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    layer = layer + b  # add bias\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return layer\n",
    "\n",
    "# Deconvolutional block\n",
    "def deconv_block(layer, W, b, activation_fn=tf.nn.relu, batch_norm=None):\n",
    "    layer = tf.nn.conv2d(layer, W, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    layer = layer + b\n",
    "    if batch_norm:\n",
    "        layer = tf.contrib.layers.batch_norm(layer, epsilon=1e-5, scope=batch_norm)\n",
    "    layer = activation_fn(layer)\n",
    "    return layer\n",
    "\n",
    "# Fully connected layer\n",
    "def fully_connected(layer, W, b, use_relu=True):\n",
    "    layer = tf.matmul(layer, W) + b\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "# Flatten layer\n",
    "def flatten(layer):\n",
    "    shape = layer.get_shape()\n",
    "    features = np.array(shape[1:4], dtype=np.int32).prod()\n",
    "    flattened = tf.reshape(layer, [-1, features])\n",
    "    return flattened, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_images = data.test.next_batch(16)[0]\n",
    "plot_images(sample_images, name='Sample Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(image, reuse=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse):\n",
    "        # 1st convolutional layer\n",
    "        W_conv1 = weight(shape=[filter_size, filter_size, image_channel, conv1_size], name='D_W_conv1')\n",
    "        b_conv1 = bias(shape=conv1_size, name='D_b_conv1')\n",
    "        conv1 = conv_block(image, W_conv1, b_conv1)\n",
    "        # 2nd convolutional layer\n",
    "        W_conv2 = weight(shape=[filter_size, filter_size, conv1_size, conv2_size], name='D_W_conv2')\n",
    "        b_conv2 = bias(shape=conv2_size, name='D_b_conv2')\n",
    "        conv2 = conv_block(conv1, W_conv2, b_conv2)\n",
    "        # 2nd convolutional layer\n",
    "        W_conv3 = weight(shape=[filter_size, filter_size, conv2_size, conv3_size], name='D_W_conv3')\n",
    "        b_conv3 = bias(shape=conv3_size, name='D_b_conv3')\n",
    "        conv3 = conv_block(conv2, W_conv3, b_conv3)\n",
    "        # Flatten\n",
    "        flattened, flat_size = flatten(layer=conv3)\n",
    "        # 1st Fully connected layer\n",
    "        W_fc1 = weight(shape=[flat_size, fc1_size], name='D_W_fc1')\n",
    "        b_fc1 = bias(shape=fc1_size, name='D_b_fc1')\n",
    "        fc1 = fully_connected(flattened, W_fc1, b_fc1)\n",
    "        # 2nd Fully connected layer\n",
    "        W_fc2 = weight(shape=[fc1_size, fc2_size], name='D_W_fc2')\n",
    "        b_fc2 = bias(shape=fc2_size, name='D_b_fc2')\n",
    "        fc2 = fully_connected(fc1, W_fc2, b_fc2)\n",
    "        # Classification layer\n",
    "        W_classify = weight(shape=[fc1_size, fc3_size], name='D_W_classify')\n",
    "        b_classify = bias(shape=fc3_size, name='D_b_classify')\n",
    "        classify = fully_connected(fc1, W_classify, b_classify, use_relu=False)\n",
    "        return classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(noise, batch_size, noise_dim):\n",
    "    scale = (image_size + image_size)  # 56  168-3channels\n",
    "    up_scale = scale * scale  # 3,136  28,224\n",
    "    # 1st Deconvolutional block\n",
    "    g_deconv_W1 = weight(shape=[z_dim, up_scale], name='G_W_deconv1')\n",
    "    g_deconv_b1 = bias(shape=up_scale, name='G_b_deconv1')\n",
    "    g_deconv_1 = tf.matmul(noise, g_deconv_W1) + g_deconv_b1\n",
    "    g_deconv_1 = tf.reshape(g_deconv_1, [-1, scale, scale, image_channel])\n",
    "    g_deconv_1 = tf.contrib.layers.batch_norm(g_deconv_1, epsilon=1e-5, scope='bn_G1')\n",
    "    g_deconv_1 = tf.nn.relu(g_deconv_1)\n",
    "    # 2nd Deconvolutional block\n",
    "    g_deconv_W2 = weight(shape=[deconv_filter, deconv_filter, image_channel, noise_dim//2], name='G_W_deconv2')\n",
    "    g_deconv_b2 = bias(shape=noise_dim//2, name='G_b_deconv2')\n",
    "    g_deconv_2 = deconv_block(g_deconv_1, g_deconv_W2, g_deconv_b2, batch_norm='bn_G2')\n",
    "    g_deconv_2 = tf.image.resize_images(g_deconv_2, [scale, scale])\n",
    "    # 3rd Deconvolutional block\n",
    "    g_deconv_W3 = weight(shape=[deconv_filter, deconv_filter, noise_dim//2, noise_dim//4], name='G_W_deconv3')\n",
    "    g_deconv_b3 = bias(shape=noise_dim//4, name='G_b_deconv3')\n",
    "    g_deconv_3 = deconv_block(g_deconv_2, g_deconv_W3, g_deconv_b3, batch_norm='bn_G3')\n",
    "    g_deconv_3 = tf.image.resize_images(g_deconv_3, [scale, scale])\n",
    "    # Final Deconvolutional block\n",
    "    g_deconv_W4 = weight(shape=[1, 1, noise_dim//4, image_channel], name='G_W_image')\n",
    "    g_deconv_b4 = bias(shape=image_channel, name='G_b_image')\n",
    "    image = deconv_block(g_deconv_3, g_deconv_W4, g_deconv_b4, activation_fn=tf.nn.sigmoid)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "z_dim = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gen_img = generator(z_placeholder, 1, z_dim)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    test_img = sess.run(gen_img, feed_dict={z_placeholder: z_batch})\n",
    "    print(test_img.shape)\n",
    "    plt.title('Test image')\n",
    "    plt.imshow(test_img.reshape([image_size, image_size]), interpolation='bicubic', cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dim], name='z_placeholder')\n",
    "X_placeholder = tf.placeholder(tf.float32, [None, image_size_flat], name='X_placeholder')\n",
    "X_image = tf.reshape(X_placeholder, [-1, image_size, image_size, image_channel])\n",
    "\n",
    "# Genenrated img\n",
    "Gz = generator(z_placeholder, batch_size, z_dim)\n",
    "# Discriminator\n",
    "# Prob. for real img\n",
    "Dx = discriminator(X_image)\n",
    "# Prob. for generated img\n",
    "Dg = discriminator(Gz, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator loss\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "# Generator loss\n",
    "g_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_vars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in t_vars if 'D_' in var.name]\n",
    "g_vars = [var for var in t_vars if 'G_' in var.name]\n",
    "\n",
    "print([var.name for var in d_vars])\n",
    "print([var.name for var in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator optimization\n",
    "d_opt_real = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(d_loss_real, var_list=d_vars)\n",
    "d_opt_fake = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(d_loss_fake, var_list=d_vars)\n",
    "# Generator optimization\n",
    "g_opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow's `Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# Henceforth, reuse variables\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "# Summaries\n",
    "tf.summary.scalar('Generator_Loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_Loss_Real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_Loss_Fake', d_loss_fake)\n",
    "img_4_tensorboard = generator(z_placeholder, batch_size, z_dim)\n",
    "tf.summary.image('Generated_Images', img_4_tensorboard, max_outputs=5)\n",
    "# merge all summaries\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# Directories\n",
    "tensorboard_dir = 'tensorboard/'\n",
    "logdir = os.path.join(tensorboard_dir, '{:%d-%b-%Y  %H-%M-%S-%p}'.format(dt.datetime.now()))\n",
    "save_path = 'models/'\n",
    "\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "\n",
    "# Create checkpoint dir\n",
    "if tf.gfile.Exists(save_path):\n",
    "    if len(tf.gfile.ListDirectory(save_path)) > 1:\n",
    "        saver.restore(sess=sess, save_path=save_path)\n",
    "else:\n",
    "    tf.gfile.MakeDirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_start = dt.datetime.now()\n",
    "# Pre-train discriminator\n",
    "for i in range(100):\n",
    "    fake_img_batch = np.random.normal(0, 1, [batch_size, z_dim])\n",
    "    real_img_batch = data.test.next_batch(batch_size)[0]\n",
    "    _, _, d_real, d_fake = sess.run([d_opt_fake, d_opt_real, \n",
    "                                     d_loss_real, d_loss_fake],\n",
    "                                    feed_dict={X_placeholder: real_img_batch, \n",
    "                                               z_placeholder: fake_img_batch})\n",
    "\n",
    "    sys.stdout.write('\\rIters: {:,}\\tDiscriminator\\'s loss:– real: {:.6f} fake: {:.6f}\\tTraining time: {}'\n",
    "                     .format(i+1, d_real, d_fake, dt.datetime.now() - train_start))\n",
    "\n",
    "# Train generator & discriminator together (dual each other)\n",
    "train_start = dt.datetime.now()\n",
    "for i in range(iterations):\n",
    "    real_img_batch = data.test.next_batch(batch_size)[0]\n",
    "    fake_img_batch = np.random.normal(0, 1, [batch_size, z_dim])\n",
    "    # Train discriminator\n",
    "    _, _, d_real, d_fake = sess.run([d_opt_fake, d_opt_real,\n",
    "                                     d_loss_real, d_loss_fake],\n",
    "                                    feed_dict={X_placeholder: real_img_batch,\n",
    "                                               z_placeholder: fake_img_batch})\n",
    "    # Train generator\n",
    "    gen_img = np.random.normal(0, 1, size=[batch_size, z_dim])\n",
    "    _, gen_loss = sess.run([g_opt, g_loss], feed_dict={z_placeholder: gen_img})\n",
    "    \n",
    "    # Updating tensorboard\n",
    "    if i % 10 == 0:\n",
    "        # save model chkpt\n",
    "        saver.save(sess=sess, save_path=save_path)\n",
    "        # update tensorboard\n",
    "        gen_img = np.random.normal(0, 1, size=[batch_size, z_dim])\n",
    "        summary = sess.run(merged, feed_dict={X_placeholder: real_img_batch,\n",
    "                                              z_placeholder: gen_img})\n",
    "        writer.add_summary(summary=summary, global_step=i)\n",
    "    # Logging\n",
    "    if i % 1000 == 0:\n",
    "        # Every 1000 iterations, show a generated image\n",
    "        print(\"\\tIterations: {:,} at {:%a %h %d, %Y at %H:%M:%S %p}\".format(i, dt.datetime.now()))\n",
    "        gen_img = np.random.normal(0, 1, size=[1, z_dim])\n",
    "        generated_images = generator(z_placeholder, 1, z_dim)\n",
    "        images = sess.run(generated_images, {z_placeholder: gen_img})\n",
    "        plt.imshow(images[0].reshape([image_size, image_size]), interpolation='bicubic', cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "        # Show discriminator's estimate\n",
    "        im = images[0]\n",
    "        result = discriminator(tf.reshape(X_placeholder, [-1, image_size, image_size, image_channel]))\n",
    "        estimate = sess.run(result, {X_placeholder: np.reshape(im, [-1, image_size_flat])})\n",
    "        print(\"Estimate: {}\\n\".format(estimate))\n",
    "    sys.stdout.write('\\rIterations: {:,}\\tTraining time: {}\\td_loss_fake: {:.4f}\\td_loss_real: {:.4f}\\tg_loss: {:.4f}'\n",
    "                     .format(i+1, dt.datetime.now() - train_start, d_fake, d_real, gen_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
