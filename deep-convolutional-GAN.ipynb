{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Convolutional Generative Adversarial Network (DCGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import ImageDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = ImageDataset(data_dir='datasets/flowers/', size=50, flatten=False, grayscale=False)\n",
    "# data.create()\n",
    "# data.save('datasets/saved/data.pkl')\n",
    "data = data.load('datasets/saved/data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, _, X_test, _ = data.train_test_split(test_size=0.1)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_size = data.size\n",
    "image_channel = data.channels\n",
    "image_size_flat = image_size * image_size * image_channel\n",
    "print('size: {}\\tchannel: {}\\t flattened: {:,}'.format(image_size, image_channel, image_size_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_prob = 0.8\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-3\n",
    "batch_size = 24\n",
    "iterations = 10000   # 10k\n",
    "save_interval = 100  # 100\n",
    "log_interval = 1000  # 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_images(imgs, name=None):\n",
    "    grid = int(np.sqrt(len(imgs)))\n",
    "    fig, axes = plt.subplots(grid, grid)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    if name:\n",
    "        plt.suptitle(name)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(imgs[i].reshape([image_size, image_size]), cmap='binary', interpolation='bicubic')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Discriminator `(Deep Convolutional Neural Net)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def discriminator(image, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Building 'AlexNet'\n",
    "        network = tf.reshape(image, shape=[-1, image_size, image_size, image_channel])\n",
    "        # 1st convnet\n",
    "        network = tflearn.conv_2d(network, nb_filter=16, filter_size=11, strides=4, activation='relu',)\n",
    "        network = tflearn.max_pool_2d(network, kernel_size=3, strides=2)\n",
    "        network = tflearn.batch_normalization(network)\n",
    "        # 2nd convnet\n",
    "        network = tflearn.conv_2d(network, nb_filter=32, filter_size=5, activation='relu')\n",
    "        network = tflearn.max_pool_2d(network, kernel_size=3, strides=2)\n",
    "        network = tflearn.batch_normalization(network)\n",
    "        # 3, 4, 5 convnet\n",
    "        network = tflearn.conv_2d(network, nb_filter=64, filter_size=3, activation='relu')\n",
    "        network = tflearn.conv_2d(network, nb_filter=128, filter_size=3, activation='relu')\n",
    "        network = tflearn.conv_2d(network, nb_filter=64, filter_size=3, activation='relu')\n",
    "        network = tflearn.max_pool_2d(network, kernel_size=3, strides=2)\n",
    "        network = tflearn.batch_normalization(network)\n",
    "        # Flatten\n",
    "        network = tflearn.flatten(network)\n",
    "        # 1st fully connected\n",
    "        network = tflearn.fully_connected(network, n_units=256, activation='tanh')\n",
    "        network = tflearn.dropout(network, keep_prob)\n",
    "        # 2nd fully connected\n",
    "        network = tflearn.fully_connected(network, n_units=128, activation='tanh')\n",
    "        network = tflearn.dropout(network, keep_prob)\n",
    "        # 3rd fully connected\n",
    "        network = tflearn.fully_connected(network, n_units=1, activation='linear')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generator `(Deep Deconvolutional Neural Net)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generator(noise, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        x = tflearn.fully_connected(noise, n_units=256, activation='tanh')\n",
    "        x = tflearn.batch_normalization(x)\n",
    "        x = tflearn.fully_connected(x, n_units=1024, activation='tanh')  # 8*8*16=1024\n",
    "        x = tf.reshape(x, shape=[-1, 8, 8, 16])\n",
    "        x = tflearn.upsample_2d(x, 2)\n",
    "        x = tflearn.conv_2d(x, nb_filter=64, filter_size=5, activation='relu')\n",
    "        x = tflearn.conv_2d(x, nb_filter=128, filter_size=5, activation='relu')\n",
    "        x = tflearn.conv_2d(x, nb_filter=64, filter_size=5, activation='relu')\n",
    "        x = tflearn.batch_normalization(x)\n",
    "        x = tflearn.upsample_2d(x, kernel_size=2)\n",
    "        x = tflearn.conv_2d(x, nb_filter=32, filter_size=5, activation='relu')\n",
    "        x = tflearn.batch_normalization(x)\n",
    "        x = tflearn.conv_2d(x, nb_filter=image_size_flat, filter_size=5, activation='relu')\n",
    "        x = tflearn.upsample_2d(x, kernel_size=2)\n",
    "        x = tflearn.conv_2d(x, nb_filter=16, filter_size=5, activation='relu')\n",
    "        x = tflearn.layers.flatten(x)\n",
    "        x = tflearn.fully_connected(x, n_units=image_size_flat, activation='sigmoid')\n",
    "        x = tf.reshape(x, shape=[-1, image_size, image_size, image_channel])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "z_dim = 200\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# gen_input = tflearn.input_data(shape=[None, z_dim], name='input_noise')\n",
    "# disc_input = tflearn.input_data(shape=[None, image_size_flat], name='disc_input')\n",
    "\n",
    "X_placeholder = tf.placeholder(tf.float32, shape=[None, image_size_flat], name='X_placeholder')\n",
    "Z_placeholder = tf.placeholder(tf.float32, shape=[None, z_dim], name='Z_placeholder')\n",
    "\n",
    "Gz = generator(Z_placeholder)\n",
    "Dx = discriminator(X_placeholder)\n",
    "Dg = discriminator(Gz, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator's loss\n",
    "d_real_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_fake_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "# Generator's loss\n",
    "gen_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Gz, labels=tf.ones_like(Gz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get variables for the discriminator & generator\n",
    "dis_vars = tflearn.get_layer_variables_by_scope('discriminator')\n",
    "gen_vars = tflearn.get_layer_variables_by_scope('generator')\n",
    "\n",
    "# Discriminator's optimizer\n",
    "disc_optimizer_r = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(d_real_loss, var_list=dis_vars)\n",
    "disc_optimizer_f = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(d_fake_loss, var_list=dis_vars)\n",
    "\n",
    "# Generator's Optimizer\n",
    "gen_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(gen_loss, var_list=gen_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tensorflow `Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tensorboard_dir = 'tensorboard/'\n",
    "logdir = os.path.join(tensorboard_dir, 'log/')\n",
    "save_path = 'models/'\n",
    "\n",
    "\n",
    "tf.summary.scalar('discriminator_loss_real', d_real_loss)\n",
    "tf.summary.scalar('discriminator_loss_fake', d_fake_loss)\n",
    "tf.summary.scalar('discriminator_add_loss', d_real_loss + d_fake_loss)\n",
    "tf.summary.scalar('generator_loss', gen_loss)\n",
    "tb_img = generator(Z_placeholder, reuse=True)  # Tensorboard image\n",
    "tf.summary.image('generator_image', tb_img, max_outputs=4)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)\n",
    "\n",
    "if tf.gfile.Exists(save_path):\n",
    "    if len(os.listdir(save_path)) > 1:\n",
    "        saver.restore(sess=sess, save_path=save_path)\n",
    "else:\n",
    "    tf.gfile.MakeDirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = dt.datetime.now()\n",
    "\n",
    "# Initial discriminator training\n",
    "for i in range(1, 101):\n",
    "    fake_batch = np.random.normal(0, 1, [batch_size, z_dim])\n",
    "    real_batch = data.next_batch(batch_size=batch_size)[0]\n",
    "    real_batch = np.reshape(real_batch, [-1, image_size_flat])\n",
    "    _, _, _fake_loss, _real_loss = sess.run([disc_optimizer_f, disc_optimizer_r, d_fake_loss, d_real_loss],\n",
    "                                            feed_dict={X_placeholder: real_batch, Z_placeholder: fake_batch})\n",
    "    sys.stdout.write('\\rIter: {:,}\\tLoss: real = {:.4f}\\t fake = {:.4f}'.format(i, _fake_loss, _real_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start_time = dt.datetime.now()\n",
    "\n",
    "# Training the discriminator & generator together\n",
    "for i in range(1, iterations+1):\n",
    "    \n",
    "    # Train discriminator on real & fake images\n",
    "    fake_batch = np.random.normal(0, 1, size=[batch_size, z_dim])\n",
    "    real_batch = data.next_batch(batch_size=batch_size)[0]\n",
    "    real_batch = np.reshape(real_batch, [-1, image_size_flat])\n",
    "    _, _, _fake_loss, _real_loss = sess.run([disc_optimizer_f, disc_optimizer_r, d_fake_loss, d_real_loss],\n",
    "                                                feed_dict={X_placeholder: real_batch, Z_placeholder: fake_batch})\n",
    "    \n",
    "    # Train generator to generate images\n",
    "    gen_img = np.random.normal(0, 1, size=[batch_size, z_dim])\n",
    "    _, _gen_loss = sess.run([gen_optimizer, gen_loss], feed_dict={Z_placeholder: gen_img})\n",
    "    \n",
    "    # Saving\n",
    "    if i%save_interval == 0:\n",
    "        saver.save(sess=sess, save_path=save_path)\n",
    "        summary = sess.run(merged, feed_dict={X_placeholder: real_batch, Z_placeholder:fake_batch})\n",
    "        writer.add_summary(summary=summary, global_step=i)\n",
    "    \n",
    "    # Logging: Displaying generated images @ intervals\n",
    "    if i%log_interval == 0:\n",
    "        test_noise  = np.random.normal(0, 1, size=[9, z_dim])\n",
    "        gen_test = generator(Z_placeholder)\n",
    "        test_imgs = sess.run(gen_test, feed_dict={Z_placeholder: test_noise})\n",
    "        plot_images(test_imgs, name='Iteration: {:,}\\tTest image'.format(i))\n",
    "    \n",
    "    # Log training metrics\n",
    "    sys.stdout.write('\\rIter: {:,}Generator: {:.4f}\\tDiscriminator: real = {:.4f} fake = {:.4f}\\tTime taken: {}'.format(\n",
    "        i,_gen_loss, _fake_loss, _real_loss, dt.datetime.now() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
